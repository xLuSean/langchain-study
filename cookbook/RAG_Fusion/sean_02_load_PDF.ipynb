{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sean's adaptation\n",
    "#### Goal:\n",
    "Use `JsonOutputParser` to get more stable output format when generate multi-queiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean_liu/miniconda3/envs/langchain/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/sean_liu/miniconda3/envs/langchain/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/fxpzwr797mz7hy09lrlmt2500000gn/T/ipykernel_82703/313147623.py:17: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader('../../pdf_files/',glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split text into chunks\n",
    "\n",
    "text_splitter  = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=text_chunks, \n",
    "                                    embedding=embedding,\n",
    "                                    persist_directory=\"data/vectorstore\")\n",
    "vectorstore.persist()\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# prompt = hub.pull(\"langchain-ai/rag-fusion-query-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Multi_Queries(BaseModel):\n",
    "    multi_queries: List[str]=Field(description=\"The new queries that rephrase user's query with different perspectives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "multi_queries_parser = JsonOutputParser(pydantic_object=Multi_Queries)\n",
    "multi_queries_format = multi_queries_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate)\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query.\n",
    "Generate 4 queries.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=system_prompt,\n",
    "        # input_variables=['format_instructions']\n",
    "        partial_variables={'format_instructions': multi_queries_format}\n",
    "    )\n",
    ")\n",
    "human_message = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"Generate multiple search queries related to: {original_query}\",\n",
    "        input_variables=['original_query']\n",
    "    )\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        human_message\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "generate_multi_queries =(\n",
    "{\"original_query\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "| multi_queries_parser\n",
    "| (lambda x: x['multi_queries'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What factors should be considered when evaluating LLM outputs?',\n",
       " 'How to assess LLM generation quality when using LLMs?',\n",
       " 'What are the key considerations for using LLMs to evaluate their own outputs?',\n",
       " 'What should I keep in mind when using an LLM for evaluating generated text?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_multi_queries.invoke({\"original_query\": \"What need to consider when using LLM to eval LLM generation?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def rrf(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # assumes the docs are returned in the order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1/(rank+k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc_str), score) for doc_str, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    \n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf_chain = generate_multi_queries | retriever.map() | rrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/fxpzwr797mz7hy09lrlmt2500000gn/T/ipykernel_82703/3786747218.py:14: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  (loads(doc_str), score) for doc_str, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n"
     ]
    }
   ],
   "source": [
    "input = {\"original_query\": \"What need to consider when using LLM to eval LLM generation?\"}\n",
    "final_result = rrf_chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ample, The evaluation pipeline of Vicuna (Zheng\\net al., 2023) has gained significant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interest and wide\\nusage due to its simplicity and interpretability. It\\nprompts GPT-4 to score and compare </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">candidate\\nresponses and provide explanations, making it a\\nvaluable tool for evaluation. However, it is un-\\nclear</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">how reliable LLMs are as evaluators, as they\\nare known to be sensitive to textual instructions\\nand inputs (Dong </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al., 2022; Turpin et al., 2023;\\narXiv:2305.17926v2  [cs.CL]  30 Aug 2023'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.06639344262295081</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'is not well explored. In this paper, we critically\\nexamine the LLMs-as-evaluator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paradigm and un-\\ncover a significant positional bias. Furthermore,\\nwe propose three simple yet effective methods </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to\\ncalibrate the positional bias to achieve reliable and\\nfair evaluation results.\\n7 Conclusion\\nIn this paper, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">we reveal a systematic positional\\nbias in evaluation with advanced ChatGPT/GPT-4\\nmodels: by manipulating the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">order of candidate\\nresponses during evaluation, the quality ranking'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.06401249024199844</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'evaluators to analyze the characteristics of posi-\\ntional bias in LLM evaluators. We </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">find that:\\nLLMs are sensitive to the position of responses.\\nAs shown in Table 2, in the evaluation of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Vicuna-\\n13B v.s. ChatGPT” and “Vicuna-13B v.s. Alpaca-\\n13B”, when the order was changed, LLMs provide\\ndifferent</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluation results, e.g., the win rate of\\nVicuna-13B extremely differs when Vicuna-13B is\\nevaluated as Assistant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">1 and Assistant 2.\\nTo empirically evaluate the sensitivity, we in-'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.032266458495966696</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'and reduce conflict, showcasing how calibration\\nenhances LLM robustness.\\n5.4 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fine-Grained Analysis of Evaluation\\nQuality\\nIn order to further analyze the evaluation capabili-\\nties of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model, we perform a fine-grained anal-\\nysis of the questions by dividing them into 9 cate-\\ngories following Zheng</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al. (2023). We calculate\\nthe performance of different evaluators within these\\ncategories. As shown in Figure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">6, we find that: 1)\\nIn certain complex tasks such as common-sense,'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03225806451612903</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2020a,b), question answering (Min et al., 2019),\\nROC story cloze (Cai, Tu, and Gimpel, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2017;\\nSchwartz et al., 2017), lexical inference (Levy et al.,\\n2015), visual question answering (Goyal et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al.,\\n2017), information extraction (Wang et al., 2021,\\n2022; Song et al., 2023a; Xia et al., 2023) and so </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on.\\nLLMs are pre-trained using a vast amount of data\\nfrom the internet, making it highly likely for them\\nto </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn biases present in those materials. Although'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016666666666666666</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'the LLMs are already widely adopted as a proxy of\\nhuman evaluators, the reliability of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this paradigm'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01639344262295082</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'with human intent (He et al., 2023). While hu-\\nman evaluation is treated as the most </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accurate mea-\\nsurement of model performance, it is costly and\\ntime-consuming to operate at scales. Consider-\\ning</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the potent capabilities of LLMs, researchers\\nhave started utilizing LLMs to evaluate the profi-\\nciency of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generative models in adhering to human\\ninstructions (Zheng et al., 2023; Lu et al., 2023; Li\\net al., 2023). In </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these works, Vicuna’s evaluation\\nparadigm (Zheng et al., 2023) is widely adopted,'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016129032258064516</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../../pdf_files/Large Language Models are not Fair Evaluators(2305.17926v2).pdf'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'veal that LLMs exhibit severe positional bias, com-\\n[Question]\\n{Q}\\n[The Start of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assistant 1’s response]\\n{R1}\\n[The End of Assistant 1’s response]\\n[The Start of Assistant 2’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response]\\n{R2}\\n[The End of Assistant 2’s response]\\n[System]\\nWe would like to request your feedback on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">per-\\nformance of two AI assistants in response to the user\\nquestion displayed above.\\nPlease rate the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helpfulness, relevance, accuracy, level\\nof details of their responses. Each assistant receives'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016129032258064516</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'ample, The evaluation pipeline of Vicuna \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZheng\\net al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has gained significant \u001b[0m\n",
       "\u001b[32minterest and wide\\nusage due to its simplicity and interpretability. It\\nprompts GPT-4 to score and compare \u001b[0m\n",
       "\u001b[32mcandidate\\nresponses and provide explanations, making it a\\nvaluable tool for evaluation. However, it is un-\\nclear\u001b[0m\n",
       "\u001b[32mhow reliable LLMs are as evaluators, as they\\nare known to be sensitive to textual instructions\\nand inputs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDong \u001b[0m\n",
       "\u001b[32met al., 2022; Turpin et al., 2023;\\narXiv:2305.17926v2  \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.CL\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  30 Aug 2023'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.06639344262295081\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'is not well explored. In this paper, we critically\\nexamine the LLMs-as-evaluator \u001b[0m\n",
       "\u001b[32mparadigm and un-\\ncover a significant positional bias. Furthermore,\\nwe propose three simple yet effective methods \u001b[0m\n",
       "\u001b[32mto\\ncalibrate the positional bias to achieve reliable and\\nfair evaluation results.\\n7 Conclusion\\nIn this paper, \u001b[0m\n",
       "\u001b[32mwe reveal a systematic positional\\nbias in evaluation with advanced ChatGPT/GPT-4\\nmodels: by manipulating the \u001b[0m\n",
       "\u001b[32morder of candidate\\nresponses during evaluation, the quality ranking'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.06401249024199844\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'evaluators to analyze the characteristics of posi-\\ntional bias in LLM evaluators. We \u001b[0m\n",
       "\u001b[32mfind that:\\nLLMs are sensitive to the position of responses.\\nAs shown in Table 2, in the evaluation of \u001b[0m\n",
       "\u001b[32m“Vicuna-\\n13B v.s. ChatGPT” and “Vicuna-13B v.s. Alpaca-\\n13B”, when the order was changed, LLMs provide\\ndifferent\u001b[0m\n",
       "\u001b[32mevaluation results, e.g., the win rate of\\nVicuna-13B extremely differs when Vicuna-13B is\\nevaluated as Assistant \u001b[0m\n",
       "\u001b[32m1 and Assistant 2.\\nTo empirically evaluate the sensitivity, we in-'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.032266458495966696\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'and reduce conflict, showcasing how calibration\\nenhances LLM robustness.\\n5.4 \u001b[0m\n",
       "\u001b[32mFine-Grained Analysis of Evaluation\\nQuality\\nIn order to further analyze the evaluation capabili-\\nties of the \u001b[0m\n",
       "\u001b[32mmodel, we perform a fine-grained anal-\\nysis of the questions by dividing them into 9 cate-\\ngories following Zheng\u001b[0m\n",
       "\u001b[32met al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We calculate\\nthe performance of different evaluators within these\\ncategories. As shown in Figure \u001b[0m\n",
       "\u001b[32m6, we find that: 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nIn certain complex tasks such as common-sense,'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.03225806451612903\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'2020a,b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, question answering \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMin et al., 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nROC story cloze \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCai, Tu, and Gimpel, \u001b[0m\n",
       "\u001b[32m2017;\\nSchwartz et al., 2017\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, lexical inference \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLevy et al.,\\n2015\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, visual question answering \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGoyal et \u001b[0m\n",
       "\u001b[32mal.,\\n2017\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, information extraction \u001b[0m\u001b[32m(\u001b[0m\u001b[32mWang et al., 2021,\\n2022; Song et al., 2023a; Xia et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and so \u001b[0m\n",
       "\u001b[32mon.\\nLLMs are pre-trained using a vast amount of data\\nfrom the internet, making it highly likely for them\\nto \u001b[0m\n",
       "\u001b[32mlearn biases present in those materials. Although'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.016666666666666666\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'the LLMs are already widely adopted as a proxy of\\nhuman evaluators, the reliability of \u001b[0m\n",
       "\u001b[32mthis paradigm'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.01639344262295082\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'with human intent \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHe et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. While hu-\\nman evaluation is treated as the most \u001b[0m\n",
       "\u001b[32maccurate mea-\\nsurement of model performance, it is costly and\\ntime-consuming to operate at scales. Consider-\\ning\u001b[0m\n",
       "\u001b[32mthe potent capabilities of LLMs, researchers\\nhave started utilizing LLMs to evaluate the profi-\\nciency of \u001b[0m\n",
       "\u001b[32mgenerative models in adhering to human\\ninstructions \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZheng et al., 2023; Lu et al., 2023; Li\\net al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. In \u001b[0m\n",
       "\u001b[32mthese works, Vicuna’s evaluation\\nparadigm \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZheng et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is widely adopted,'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.016129032258064516\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'../../pdf_files/Large Language Models are not Fair Evaluators\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2305.17926v2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.pdf'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'veal that LLMs exhibit severe positional bias, com-\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuestion\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mQ\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mThe Start of \u001b[0m\n",
       "\u001b[32mAssistant 1’s response\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mR1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mThe End of Assistant 1’s response\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mThe Start of Assistant 2’s \u001b[0m\n",
       "\u001b[32mresponse\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mR2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mThe End of Assistant 2’s response\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mSystem\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nWe would like to request your feedback on the \u001b[0m\n",
       "\u001b[32mper-\\nformance of two AI assistants in response to the user\\nquestion displayed above.\\nPlease rate the \u001b[0m\n",
       "\u001b[32mhelpfulness, relevance, accuracy, level\\nof details of their responses. Each assistant receives'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;36m0.016129032258064516\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
