{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sean's adaptation\n",
    "#### Goal:\n",
    "Use `JsonOutputParser` to get more stable output format when generate multi-queiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = {\n",
    "    \"doc1\": \"Climate change and economic impact.\",\n",
    "    \"doc2\": \"Public health concerns due to climate change.\",\n",
    "    \"doc3\": \"Climate change: A social perspective.\",\n",
    "    \"doc4\": \"Technological solutions to climate change.\",\n",
    "    \"doc5\": \"Policy changes needed to combat climate change.\",\n",
    "    \"doc6\": \"Climate change and its impact on biodiversity.\",\n",
    "    \"doc7\": \"Climate change: The science and models.\",\n",
    "    \"doc8\": \"Global warming: A subset of climate change.\",\n",
    "    \"doc9\": \"How climate change affects daily weather.\",\n",
    "    \"doc10\": \"The history of climate change activism.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(all_documents.values(), embedding=embedding, collection_name=\"sean\", persist_directory=\"./sean_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# prompt = hub.pull(\"langchain-ai/rag-fusion-query-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Multi_Queries(BaseModel):\n",
    "    multi_queries: List[str]=Field(description=\"The new queries that rephrase user's query with different perspectives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "multi_queries_parser = JsonOutputParser(pydantic_object=Multi_Queries)\n",
    "multi_queries_format = multi_queries_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate)\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query.\n",
    "Generate 4 queries.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=system_prompt,\n",
    "        # input_variables=['format_instructions']\n",
    "        partial_variables={'format_instructions': multi_queries_format}\n",
    "    )\n",
    ")\n",
    "human_message = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"Generate multiple search queries related to: {original_query}\",\n",
    "        input_variables=['original_query']\n",
    "    )\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        human_message\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "generate_multi_queries =(\n",
    "{\"original_query\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "| multi_queries_parser\n",
    "| (lambda x: x['multi_queries'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_multi_queries.invoke({\"original_query\": \"Climate change and economic impact.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def rrf(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # assumes the docs are returned in the order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1/(rank+k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc_str), score) for doc_str, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    \n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf_chain = generate_multi_queries | retriever.map() | rrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"original_query\": \"Climate change and economic impact.\"}\n",
    "final_result = rrf_chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
