{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ef724e",
   "metadata": {},
   "source": [
    "# Step-Back Prompting (Question-Answering)\n",
    "\n",
    "One prompting technique called \"Step-Back\" prompting can improve performance on complex questions by first asking a \"step back\" question. This can be combined with regular question-answering applications by then doing retrieval on both the original and step-back question.\n",
    "\n",
    "Read the paper [here](https://arxiv.org/abs/2310.06117)\n",
    "\n",
    "See an excellent blog post on this by Cobus Greyling [here](https://cobusgreyling.medium.com/a-new-prompt-engineering-technique-has-been-introduced-called-step-back-prompting-b00e8954cacb)\n",
    "\n",
    "In this cookbook we will replicate this technique. We modify the prompts used slightly to work better with chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da7bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67b5cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e017c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206415ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d643a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen = prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5992c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when was ChatGPT developed and released?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"was chatgpt around while trump was president?\"\n",
    "question_gen.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32667424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "search = DuckDuckGoSearchAPIWrapper(max_results=4)\n",
    "\n",
    "\n",
    "def retriever(query):\n",
    "    return search.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc28c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Republican presidential nominee former President Donald Trump speaks at a campaign rally in Allentown, Pa., Tuesday, Oct. 29, 2024. (AP Photo/Matt Rourke) Donald Trump talks to the media in 2019 in Washington D.C. As the president-elect prepares to take office, speculation surrounds potential conflicts within his newly formed Cabinet. Republican presidential nominee, former President Donald Trump dances off stage at the conclusion of a campaign rally at the J.S. Dorton Arena on November 04, 2024 in Raleigh, North Carolina. President-elect Donald Trump is poised to be at the helm as AI infrastructure develops, says OpenAI CFO Sarah Friar. Despite tensions with Elon Musk, OpenAI thrives, showcasing innovative tools like Sora. Friar anticipates AI advances in 2024, collaborating with Microsoft while managing growth challenges.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c77443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"April 23, 2023 - OpenAI released ChatGPT plugins, GPT-3.5 with browsing, and GPT-4 with browsing in ALPHA. ... or will the outcome of those cases slow the development of future training models? Unlike previous AI models, ChatGPT was developed in a way that keeps up with follow up questions and giving answers that felt personal and relevant. ... In 2023, OpenAI released GPT-4 to ChatGPT Plus subscribers for a new level of detail and precision to the model's responses. This update allowed ChatGPT to handle more complex questions and ... June 2020: GPT-3 was released, constituting a major leap in AI technology with its 175 billion parameters. It was employed to perform various tasks, such as drafting emails, writing articles, composing poetry, and generating code, showcasing its versatile applications. November 30, 2022: ChatGPT was launched using GPT-3.5, and it quickly went ... OpenAI was founded in 2015 and since then has developed and introduced ChatGPT to the public, led by CEO Sam Altman. ... ChatGPT was created by OpenAI, and released on November 30th, 2022. OpenAI has since become the world's most famous AI research and development company. CEO Sam Altman also co-founded the company and has served on the ...\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question_gen.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b257bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "# response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f48c65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a643ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert of world knowledge. \n",
    "I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. \n",
    "Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "<normal_context>\n",
    "# {normal_context}\n",
    "</normal_context>\n",
    "\n",
    "<step_back_context>\n",
    "# {step_back_context}\n",
    "</step_back_context>\n",
    "\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "\n",
    "response_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4467f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'normal_context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'step_back_context'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_owner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'langchain-ai'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_repo'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stepback-answer'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_commit_hash'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e9860e84090dcfa49a71be16483370a599223ed06be88597cc802d9c9201e914'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You are an expert of world knowledge. I am going to ask you a question. Your response should be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are not relevant.\\n\\n{normal_context}\\n{step_back_context}\\n\\nOriginal Question: {question}\\nAnswer:'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'normal_context'\u001b[0m, \u001b[32m'question'\u001b[0m, \u001b[32m'step_back_context'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'lc_hub_owner'\u001b[0m: \u001b[32m'langchain-ai'\u001b[0m,\n",
       "        \u001b[32m'lc_hub_repo'\u001b[0m: \u001b[32m'stepback-answer'\u001b[0m,\n",
       "        \u001b[32m'lc_hub_commit_hash'\u001b[0m: \u001b[32m'e9860e84090dcfa49a71be16483370a599223ed06be88597cc802d9c9201e914'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtemplate\u001b[0m=\u001b[32m'You are an expert of world knowledge. I am going to ask you a question. Your response should be \u001b[0m\n",
       "\u001b[32mcomprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they \u001b[0m\n",
       "\u001b[32mare not relevant.\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnormal_context\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mstep_back_context\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nOriginal Question: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nAnswer:'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(response_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97a6d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": question_gen,\n",
    "        # \"step_back_context\": RunnableLambda(lambda x: x[\"question\"])| question_gen | retriever,\n",
    "\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc0851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableSequence</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">first</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableParallel</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">steps__</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'normal_context'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnablePassthrough</span><span style=\"font-weight: bold\">()</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'step_back_context'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableSequence</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">first</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnablePassthrough</span><span style=\"font-weight: bold\">()</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">middle</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You are an expert at world knowledge. Your task is to step back and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:'</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FewShotChatMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">examples</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                                    <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Could the members of The Police perform lawful arrests?'</span>,\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'what can the members of The Police do?'</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>,\n",
       "                                    <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Jan Sindel’s was born in what country?'</span>,\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'what is Jan Sindel’s personal history?'</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">]</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">example_prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                                        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{input}'</span>\n",
       "                                            <span style=\"font-weight: bold\">)</span>,\n",
       "                                            <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "                                        <span style=\"font-weight: bold\">)</span>,\n",
       "                                        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'output'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                                <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{output}'</span>\n",
       "                                            <span style=\"font-weight: bold\">)</span>,\n",
       "                                            <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "                                        <span style=\"font-weight: bold\">)</span>\n",
       "                                    <span style=\"font-weight: bold\">]</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{question}'</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>\n",
       "                        <span style=\"font-weight: bold\">]</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">openai.resources.chat.completions.Completions</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x109bc8e50</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.AsyncCompletions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x109bcaf50</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">root_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.OpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x109b392d0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">root_async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.AsyncOpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x109bc8eb0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">model_name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">model_kwargs</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">openai_api_key</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">last</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StrOutputParser</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnablePassthrough</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">middle</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">last</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'normal_context'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'step_back_context'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">input_types</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are an expert of world knowledge. \\nI am going to ask you a question. Your response should be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive and not contradicted with the following context if they are relevant. \\nOtherwise, ignore them if </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">they are not relevant.\\n\\n&lt;normal_context&gt;\\n# {normal_context}\\n&lt;/normal_context&gt;\\n\\n&lt;step_back_context&gt;\\n# </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{step_back_context}\\n&lt;/step_back_context&gt;\\n\\n\\n# Original Question: {question}\\n# Answer:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRunnableSequence\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mfirst\u001b[0m=\u001b[1;35mRunnableParallel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msteps__\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'normal_context'\u001b[0m: \u001b[1;35mRunnablePassthrough\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'step_back_context'\u001b[0m: \u001b[1;35mRunnableSequence\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mfirst\u001b[0m=\u001b[1;35mRunnablePassthrough\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mmiddle\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                        \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                        \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                        \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                            \u001b[1;35mSystemMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mtemplate\u001b[0m=\u001b[32m'You are an expert at world knowledge. Your task is to step back and \u001b[0m\n",
       "\u001b[32mparaphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:'\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[1;35mFewShotChatMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mexamples\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                                    \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'input'\u001b[0m: \u001b[32m'Could the members of The Police perform lawful arrests?'\u001b[0m,\n",
       "                                        \u001b[32m'output'\u001b[0m: \u001b[32m'what can the members of The Police do?'\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m,\n",
       "                                    \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'input'\u001b[0m: \u001b[32m'Jan Sindel’s was born in what country?'\u001b[0m,\n",
       "                                        \u001b[32m'output'\u001b[0m: \u001b[32m'what is Jan Sindel’s personal history?'\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m]\u001b[0m,\n",
       "                                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mexample_prompt\u001b[0m=\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input'\u001b[0m, \u001b[32m'output'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                                        \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                            \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                                \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32minput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "                                            \u001b[1m)\u001b[0m,\n",
       "                                            \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                                        \u001b[1m)\u001b[0m,\n",
       "                                        \u001b[1;35mAIMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                            \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'output'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                                \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "                                            \u001b[1m)\u001b[0m,\n",
       "                                            \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                                        \u001b[1m)\u001b[0m\n",
       "                                    \u001b[1m]\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                                    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                    \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m\n",
       "                        \u001b[1m]\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mChatOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mclient\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mopenai.resources.chat.completions.Completions\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x109bc8e50\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<openai.resources.chat.completions.AsyncCompletions object at \u001b[0m\u001b[1;36m0x109bcaf50\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mroot_client\u001b[0m\u001b[39m=<openai.OpenAI object at \u001b[0m\u001b[1;36m0x109b392d0\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mroot_async_client\u001b[0m\u001b[39m=<openai.AsyncOpenAI object at \u001b[0m\u001b[1;36m0x109bc8eb0\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmodel_name\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmodel_kwargs\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mopenai_api_key\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mSecretStr\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mlast\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mStrOutputParser\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'question'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mRunnablePassthrough\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mmiddle\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mlast\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPromptTemplate\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33minput_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'normal_context'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'question'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'step_back_context'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33minput_types\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpartial_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mtemplate\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'You are an expert of world knowledge. \\nI am going to ask you a question. Your response should be\u001b[0m\n",
       "\u001b[32mcomprehensive and not contradicted with the following context if they are relevant. \\nOtherwise, ignore them if \u001b[0m\n",
       "\u001b[32mthey are not relevant.\\n\\n<normal_context>\\n# \u001b[0m\u001b[32m{\u001b[0m\u001b[32mnormal_context\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</normal_context>\\n\\n<step_back_context>\\n# \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32mstep_back_context\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</step_back_context\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n\\n\\n# Original Question: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n# Answer:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "test_chain = (\n",
    "    # {\n",
    "    #     # Retrieve context using the normal question\n",
    "    #     \"normal_context\": RunnableLambda(lambda x: x[\"question\"]),\n",
    "\n",
    "    #     # Retrieve context using the step-back question\n",
    "    #     # \"step_back_context\": question_gen | retriever,\n",
    "    #     \"step_back_context\": RunnableLambda(lambda x: x[\"question\"])| question_gen,\n",
    "\n",
    "    #     # Pass on the question\n",
    "    #     \"question\": lambda x: x[\"question\"],\n",
    "    # }\n",
    "# =====================================================================\n",
    "    {'normal_context': RunnablePassthrough(),\n",
    "     'step_back_context': RunnablePassthrough() | question_gen,\n",
    "     'question': RunnablePassthrough()\n",
    "     }\n",
    "\n",
    "    | response_prompt\n",
    ")\n",
    "test_chain.invoke({\"question\": question})\n",
    "rich.print(test_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce554cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChatGPT was not available during Donald Trump's presidency, which lasted from January 20, 2017, to January 20, 2021. The model was developed by OpenAI and was first released in November 2022, after Trump's term had ended. Therefore, it did not exist while he was in office.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb8dd2",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00db8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "{normal_context}\n",
    "\n",
    "Original Question: {question}\n",
    "Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06335ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question (only the first 3 results)\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e0e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChatGPT, developed by OpenAI, was released in November 2022, which means it was not available during Donald Trump's presidency, which lasted from January 20, 2017, to January 20, 2021. Therefore, ChatGPT did not exist while Trump was in office.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9e5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
