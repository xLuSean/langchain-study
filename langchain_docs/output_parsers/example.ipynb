{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain:输出封装OutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "prompt1='说出几种常见的水果'\n",
    "prompt2=\"输出20以内的素数\"\n",
    "llm=ChatOpenAI()\n",
    "comma_parser=CommaSeparatedListOutputParser()\n",
    "response=llm.invoke(prompt1)\n",
    "print(\"===模型原始输出===\")\n",
    "print(response.content)\n",
    "print('===CommaSeparatedListOutputParser解析输出===')\n",
    "print(comma_parser.parse(response.content))\n",
    "response=llm.invoke(prompt2)\n",
    "print(\"===模型原始输出===\")\n",
    "print(response.content)\n",
    "print('===CommaSeparatedListOutputParser解析输出===')\n",
    "print(comma_parser.parse(response.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 针对prompt1模型输出的结果中的没有,所以CommaSeparatedListOutputParser解析器没有正确解析出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 langchain_core中的解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目前langchain_core.output_parsers中的OutputParser类主要包括以下几种(虚拟类不列出)：\n",
    "\n",
    "* json类：JsonOutputParser，将结果解析成json串。\n",
    "* list类： CommaSeparatedListOutputParser、MarkdownListOutputParser和NumberedListOutputParser，将结果解析成类似List的对象。CommaSeparatedListOutputParser其结果是对LLM模型返回的字符串使用(,)进行分割得到的List。后面两种分别采用正则表达式从LLM模型返回的字符串中提取出符合规则的部分。\n",
    "* string类。StrOutputParser，直接输出LLM模型返回的结果。\n",
    "* xml类。XMLOutputParser，将LLM模型返回的结果解析成xml。\n",
    "* pydantic类。PydanticOutputParser, 第2部分介绍。\n",
    "* openai_function和openai_tools类：这两类可以帮助提取出LLM产生的函数调用的参数。openai_function系列针对的是使用function_call字段表示函数调用的参数的情况，后者针对的使用tool_calls字段表示function call的参数的情况(GPT系列模型采用的是这种方式)。这里只介绍openai_tools类。主要包括JsonOutputKeyToolsParser、JsonOutputToolsParser和PydanticToolsParser。其用法举例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.outputs import ChatGeneration\n",
    "#注意引用方法\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "tools=[{ \n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"sum\",\n",
    "                \"description\": \"加法器，计算一组数的和\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"numbers\": {\"type\": \"array\", \"items\": { \"type\": \"number\"}}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "llm=ChatOpenAI(model_kwargs={\"tools\":tools})\n",
    "\n",
    "response=llm.invoke(\"计算一组数据的和:13,49837,3489,23423\")\n",
    "print(response)\n",
    "response=ChatGeneration(message=response)\n",
    "\n",
    "parser=JsonOutputToolsParser()\n",
    "print(\"---解析后结果---\")\n",
    "print(parser.parse_result([response]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 langchain中的输出封装\n",
    "* boolean: BooleanOutputParser\t返回True或False\n",
    "* combining: CombiningOutputParser\t同时将多个输出解析成同一个格式\n",
    "* datetime: DatetimeOutputParser\t将日期转化成特定格式\n",
    "* enum: EnumOutputParser\t将LLM模型输出解析成enum\n",
    "* fix: OutputFixingParser\t可以自动修复异常并重新解析\n",
    "* pandas_dataframe: PandasDataFrameOutputParser\t使用pandas.dataframe的format对LLM进行解析\n",
    "* regex: RegexParser\t使用正则表达式对LLM模型返回进行解析\n",
    "* regex_dict: RegexDictParser\t功能同上\n",
    "* retry: RetryOutputParser、RetryWithErrorOutputParser\t可以自动修复异常并重新解析\n",
    "* structured\tStructuredOutputParser\t将LLM模型输出进行结构化解析\n",
    "* yaml\tYamlOutputParser\t提取LLM模型输出中的YAML部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然OutputParser可以对LLM的输出结果进行解析，但这种使用方式用户体验并不好，正如第一个案例中针对prompt1的输出结果，因为无法确定LLM模型输出的结果中是否使用,，所以解析结果无法掌控。可以使用OutputParser类的get_format_instructions()方法来调整LLM模型输出。举例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "parser=DatetimeOutputParser()\n",
    "format_instruction=parser.get_format_instructions()\n",
    "llm=ChatOpenAI()\n",
    "prompt=PromptTemplate.from_template(template=\"计算机时间的起始时间是什么时候？{format_instruction}\")\n",
    "prompt=prompt.format(format_instruction=format_instruction)\n",
    "response=llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.output_parsers import JsonOutputKeyToolsParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "format_instruction = parser.get_format_instructions()\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "prompt=PromptTemplate.from_template(template=\"计算机时间的起始时间是什么时候？{format_instruction}\")\n",
    "prompt=prompt.format(format_instruction=format_instruction)\n",
    "response=llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field,validator\n",
    "import re\n",
    "\n",
    "class Func_Json(BaseModel):\n",
    "    name:str=Field(description=\"函数名称，只能由字母组成并且长度不超过10\")\n",
    "    description:str=Field(description=\"函数描述\")\n",
    "\n",
    "    @validator(\"name\")\n",
    "    def valid_name(cls,field):\n",
    "        if re.match(r'^[a-zA-Z]+$',field) and len(field)<10:\n",
    "            return field\n",
    "        else:\n",
    "            raise ValueError(\"函数名称不符合要求\")\n",
    "\n",
    "print(Func_Json(name=\"sum\",description=\"求一组数据的和\"))\n",
    "print(Func_Json(name='sum2',description=\"求一组数据的和\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field,validator\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class New_List(BaseModel):\n",
    "    item:List[str]\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "parser = PydanticOutputParser(pydantic_object=New_List)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"请列出10种常见的水果。{format_instruction}\")\n",
    "prompt = prompt.format(format_instruction = parser.get_format_instructions())\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field,validator, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "class New_List(BaseModel):\n",
    "    item1: List[str] = Field(description=\"name appears in the query\")\n",
    "    item2: List[str] = Field(description=\"terminology appears in the query\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=New_List)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"20世紀初期海森堡和薛丁格發展出量子力學 {format_instruction}\")\n",
    "prompt = prompt.format(format_instruction = parser.get_format_instructions())\n",
    "\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "# print(response)\n",
    "print(response.content)\n",
    "\n",
    "json_response = json.loads(response.content)\n",
    "print(json_response['item1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field,validator, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "class New_List(BaseModel):\n",
    "    item1: List = Field(description=\"name appears in the query\")\n",
    "    item2: List = Field(description=\"terminology appears in the query\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=New_List)\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\"20世紀初期海森堡和薛丁格發展出量子力學 {format_instruction}\")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{input} {format_instruction}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# prompt = prompt.format(format_instruction = parser.get_format_instructions())\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "res = chain.invoke(\"20世紀初期海森堡和薛丁格發展出量子力學\")\n",
    "print(type(res))\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
