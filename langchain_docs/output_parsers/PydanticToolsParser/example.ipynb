{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [The best library for structured LLM output](https://simmering.dev/blog/structured_output/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Set up a Pydantic model for the structured output\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str = Field(description=\"name of the entity\")\n",
    "    label: Literal[\"PERSON\", \"ORGANIZATION\", \"LOCATION\"]\n",
    "\n",
    "\n",
    "class ExtractEntities(BaseModel):\n",
    "    entities: List[Entity]\n",
    "\n",
    "\n",
    "# Choose a model\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.0)\n",
    "\n",
    "# Force the model to always use the ExtractEntities schema\n",
    "llm_with_tools = llm.bind_tools([ExtractEntities], tool_choice=\"ExtractEntities\")\n",
    "\n",
    "# Add a parser to convert the LLM output to a Pydantic object\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[ExtractEntities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities=[Entity(name='BioNTech SE', label='ORGANIZATION'), Entity(name='InstaDeep', label='ORGANIZATION'), Entity(name='Tunis', label='LOCATION'), Entity(name='U.K.', label='LOCATION')]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"BioNTech SE is set to acquire InstaDeep, \\\n",
    "a Tunis-born and U.K.-based artificial intelligence \\\n",
    "(AI) startup, for up to £562 million\\\n",
    "\"\"\"\n",
    "res = chain.invoke(text)[0]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[{'name': 'BioNTech SE', 'label': 'ORGANIZATION'}, {'name': 'InstaDeep', 'label': 'ORGANIZATION'}, {'name': 'Tunis', 'label': 'LOCATION'}, {'name': 'U.K.', 'label': 'LOCATION'}]\n"
     ]
    }
   ],
   "source": [
    "print(type(res.dict()))\n",
    "print(res.dict().get(\"entities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractEntities(entities=[Entity(name='BioNTech SE', label='ORGANIZATION'), Entity(name='InstaDeep', label='ORGANIZATION'), Entity(name='Tunis', label='LOCATION'), Entity(name='U.K.', label='LOCATION')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Set up a Pydantic model for the structured output\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str = Field(description=\"name of the entity\")\n",
    "    label: Literal[\"PERSON\", \"ORGANIZATION\", \"LOCATION\"]\n",
    "\n",
    "\n",
    "class ExtractEntities(BaseModel):\n",
    "    entities: List[Entity]\n",
    "\n",
    "\n",
    "# Choose a model\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.0)\n",
    "\n",
    "# Force the model to always use the ExtractEntities schema\n",
    "llm_with_tools = llm.bind_tools([ExtractEntities], tool_choice=\"ExtractEntities\")\n",
    "\n",
    "# Add a parser to convert the LLM output to a Pydantic object\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[ExtractEntities])\n",
    "\n",
    "text = \"\"\"BioNTech SE is set to acquire InstaDeep, \\\n",
    "a Tunis-born and U.K.-based artificial intelligence \\\n",
    "(AI) startup, for up to £562 million\\\n",
    "\"\"\"\n",
    "chain.invoke(text)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Set up a Pydantic model for the structured output\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str = Field(description=\"name of the entity\")\n",
    "    label: Literal[\"PERSON\", \"ORGANIZATION\", \"LOCATION\"]\n",
    "\n",
    "\n",
    "class ExtractEntities(BaseModel):\n",
    "    entities: List[Entity]\n",
    "\n",
    "\n",
    "# Choose a model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Distill the entities from the user's input, if no available return empty.\\n\\\n",
    "            User:{query}\\n\",\n",
    "            input_variables=[\"query\"],\n",
    "            )\n",
    "\n",
    "# Force the model to always use the ExtractEntities schema\n",
    "llm_with_tools = llm.bind_tools([ExtractEntities], tool_choice=\"ExtractEntities\")\n",
    "\n",
    "# Add a parser to convert the LLM output to a Pydantic object\n",
    "chain = prompt | llm_with_tools | PydanticToolsParser(tools=[ExtractEntities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_M61So3JM99t91y36GCwdXCBu', 'function': {'arguments': '{\"entities\":[{\"name\":\"John Doe\",\"label\":\"PERSON\"},{\"name\":\"OpenAI\",\"label\":\"ORGANIZATION\"},{\"name\":\"New York\",\"label\":\"LOCATION\"}]}', 'name': 'ExtractEntities'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 76, 'total_tokens': 110, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None}, id='run-f4450b31-631c-4252-b7ca-0b6a58ef7a23-0', tool_calls=[{'name': 'ExtractEntities', 'args': {'entities': [{'name': 'John Doe', 'label': 'PERSON'}, {'name': 'OpenAI', 'label': 'ORGANIZATION'}, {'name': 'New York', 'label': 'LOCATION'}]}, 'id': 'call_M61So3JM99t91y36GCwdXCBu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 76, 'output_tokens': 34, 'total_tokens': 110})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[ExtractEntities(entities=[Entity(name='BioNTech SE', label='ORGANIZATION'), Entity(name='InstaDeep', label='ORGANIZATION'), Entity(name='Tunis', label='LOCATION'), Entity(name='U.K.', label='LOCATION')])]\n"
     ]
    }
   ],
   "source": [
    "text\n",
    "res = chain.invoke({\"query\": text})\n",
    "print(type(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractEntities(entities=[Entity(name='BioNTech SE', label='ORGANIZATION'), Entity(name='InstaDeep', label='ORGANIZATION'), Entity(name='Tunis', label='LOCATION'), Entity(name='U.K.', label='LOCATION')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entity(name='BioNTech SE', label='ORGANIZATION'),\n",
       " Entity(name='InstaDeep', label='ORGANIZATION'),\n",
       " Entity(name='Tunis', label='LOCATION'),\n",
       " Entity(name='U.K.', label='LOCATION')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioNTech SE ORGANIZATION\n",
      "InstaDeep ORGANIZATION\n",
      "Tunis LOCATION\n",
      "U.K. LOCATION\n"
     ]
    }
   ],
   "source": [
    "for entitr in res[0].entities:\n",
    "    print(entitr.name, entitr.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
