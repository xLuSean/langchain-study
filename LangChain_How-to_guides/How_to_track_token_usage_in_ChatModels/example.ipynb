{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to track token usage in ChatModels](https://python.langchain.com/v0.2/docs/how_to/chat_token_usage_tracking/)\n",
    "\n",
    "Using AIMessage.usage_metadata\n",
    "A number of model providers return token usage information as part of the chat generation response. When available, this information will be included on the AIMessage objects produced by the corresponding model.\n",
    "\n",
    "LangChain AIMessage objects include a usage_metadata attribute. When populated, this attribute will be a UsageMetadata dictionary with standard keys (e.g., \"input_tokens\" and \"output_tokens\").\n",
    "\n",
    "Examples:\n",
    "\n",
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "openai_response = llm.invoke(\"hello\")\n",
    "openai_response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using AIMessage.response_metadata\n",
    "Metadata from the model response is also included in the AIMessage response_metadata attribute. These data are typically not standardized. Note that different providers adopt different conventions for representing token counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI: {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'OpenAI: {openai_response.response_metadata[\"token_usage\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-403cf831-0fde-4d96-a403-37c8c47d9cd3-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "Some providers support token count metadata in a streaming context.\n",
    "\n",
    "OpenAI\n",
    "For example, OpenAI will return a message chunk at the end of a stream with token usage information. This behavior is supported by langchain-openai >= 0.1.9 and can be enabled by setting stream_usage=True. This attribute can also be set when ChatOpenAI is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content='Hello' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content='!' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' How' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' can' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' I' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' assist' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' you' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content=' today' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content='?' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'} id='run-ea334cc7-6875-4925-8871-5a403fb1c69d'\n",
      "content='' id='run-ea334cc7-6875-4925-8871-5a403fb1c69d' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "aggregate = None\n",
    "for chunk in llm.stream(\"hello\", stream_usage=True):\n",
    "    print(chunk)\n",
    "    aggregate = chunk if aggregate is None else aggregate + chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Hello! How can I assist you today?', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, id='run-ea334cc7-6875-4925-8871-5a403fb1c69d', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "{'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}\n"
     ]
    }
   ],
   "source": [
    "print(aggregate.content)\n",
    "print(aggregate.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To disable streaming token counts for OpenAI, set stream_usage to False, or omit it from the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content='Hello' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content='!' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' How' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' can' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' I' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' assist' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' you' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content=' today' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content='?' id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n",
      "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'} id='run-154157e1-21d7-4e61-94a1-08c689cd0f99'\n"
     ]
    }
   ],
   "source": [
    "aggregate = None\n",
    "for chunk in llm.stream(\"hello\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the below example, where we return output structured to a desired schema, but can still observe token usage streamed from intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token usage: {'input_tokens': 74, 'output_tokens': 26, 'total_tokens': 100}\n",
      "\n",
      "setup='Why did the scarecrow win an award?' punchline='Because he was outstanding in his field!'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    stream_usage=True,\n",
    ")\n",
    "# Under the hood, .with_structured_output binds tools to the\n",
    "# chat model and appends a parser.\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "\n",
    "async for event in structured_llm.astream_events(\"Tell me a joke\", version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_end\":\n",
    "        print(f'Token usage: {event[\"data\"][\"output\"].usage_metadata}\\n')\n",
    "    elif event[\"event\"] == \"on_chain_end\":\n",
    "        print(event[\"data\"][\"output\"])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using callbacks\n",
    "There are also some API-specific callback context managers that allow you to track token usage across multiple calls. It is currently only implemented for the OpenAI API and Bedrock Anthropic API.\n",
    "\n",
    "### OpenAI\n",
    "Let's first look at an extremely simple example of tracking token usage for a single Chat model call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 28\n",
      "\tPrompt Tokens: 11\n",
      "\tCompletion Tokens: 17\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $1.185e-05\n"
     ]
    }
   ],
   "source": [
    "# !pip install -qU langchain-community wikipedia\n",
    "\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    stream_usage=True,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything inside the context manager will get tracked. Here's an example of using it to track multiple calls in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke\")\n",
    "    result2 = llm.invoke(\"Tell me a joke\")\n",
    "    print(cb.total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 29\n",
      "\tPrompt Tokens: 11\n",
      "\tCompletion Tokens: 18\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $1.2449999999999998e-05\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    for chunk in llm.stream(\"Tell me a joke\"):\n",
    "        pass\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a chain or agent with multiple steps in it is used, it will track all those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, load_tools\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You're a helpful assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Hummingbird'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Hummingbird\n",
      "Summary: Hummingbirds are birds native to the Americas and comprise the biological family Trochilidae. With approximately 366 species and 113 genera, they occur from Alaska to Tierra del Fuego, but most species are found in Central and South America. As of 2024, 21 hummingbird species are listed as endangered or critically endangered, with numerous species declining in population.\n",
      "Hummingbirds have varied specialized characteristics to enable rapid, maneuverable flight: exceptional metabolic capacity, adaptations to high altitude, sensitive visual and communication abilities, and long-distance migration in some species. Among all birds, male hummingbirds have the widest diversity of plumage color, particularly in blues, greens, and purples. Hummingbirds are the smallest mature birds, measuring 7.5–13 cm (3–5 in) in length. The smallest is the 5 cm (2.0 in) bee hummingbird, which weighs less than 2.0 g (0.07 oz), and the largest is the 23 cm (9 in) giant hummingbird, weighing 18–24 grams (0.63–0.85 oz). Noted for long beaks, hummingbirds are specialized for feeding on flower nectar, but all species also consume small insects.\n",
      "They are known as hummingbirds because of the humming sound created by their beating wings, which flap at high frequencies audible to other birds and humans. They hover at rapid wing-flapping rates, which vary from around 12 beats per second in the largest species to 80 per second in small hummingbirds.\n",
      "Hummingbirds have the highest mass-specific metabolic rate of any homeothermic animal. To conserve energy when food is scarce and at night when not foraging, they can enter torpor, a state similar to hibernation, and slow their metabolic rate to 1⁄15 of its normal rate. While most hummingbirds do not migrate, the rufous hummingbird has one of the longest migrations among birds, traveling twice per year between Alaska and Mexico, a distance of about 3,900 miles (6,300 km).\n",
      "Hummingbirds split from their sister group, the swifts and treeswifts, around 42 million years ago. The oldest known fossil hummingbird is Eurotrochilus, from the Rupelian Stage of Early Oligocene Europe.\n",
      "\n",
      "Page: Bee hummingbird\n",
      "Summary: The bee hummingbird, zunzuncito or Helena hummingbird (Mellisuga helenae) is a species of hummingbird, native to the island of Cuba in the Caribbean. It is the smallest known bird. The bee hummingbird feeds on nectar of flowers and bugs found in Cuba.\n",
      "\n",
      "\n",
      "\n",
      "Page: Hummingbird hawk-moth\n",
      "Summary: The hummingbird hawk-moth (Macroglossum stellatarum) is a species of hawk moth found across temperate regions of Eurasia. The species is named for its similarity to hummingbirds, as they feed on the nectar of tube-shaped flowers using their long proboscis while hovering in the air; this resemblance is an example of convergent evolution. \n",
      "The hummingbird hawk-moth was first described by Carl Linnaeus in his 1758 10th edition of Systema Naturae. As of 2018, its entire genome and mitogenome have been sequenced.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'fastest bird species'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of birds by flight speed\n",
      "Summary: This is a list of the fastest flying birds in the world. A bird's velocity is necessarily variable; a hunting bird will reach much greater speeds while diving to catch prey than when flying horizontally. The bird that can achieve the greatest airspeed is the peregrine falcon (Falco peregrinus), able to exceed 320 km/h (200 mph) in its dives. A close relative of the common swift, the white-throated needletail (Hirundapus caudacutus), is commonly reported as the fastest bird in level flight with a reported top speed of 169 km/h (105 mph). This record remains unconfirmed as the measurement methods have never been published or verified. The record for the fastest confirmed level flight by a bird is 111.5 km/h (69.3 mph) held by the common swift.\n",
      "\n",
      "Page: Fastest animals\n",
      "Summary: This is a list of the fastest animals in the world, by types of animal.\n",
      "\n",
      "Page: Swift (bird)\n",
      "Summary: The swifts are a family, Apodidae, of highly aerial birds. They are superficially similar to swallows, but are not closely related to any passerine species. Swifts are placed in the order Apodiformes with hummingbirds. The treeswifts are closely related to the true swifts, but form a separate family, the Hemiprocnidae.\n",
      "Resemblances between swifts and swallows are due to convergent evolution, reflecting similar life styles based on catching insects in flight.\n",
      "The family name, Apodidae, is derived from the Greek ἄπους (ápous), meaning \"footless\", a reference to the small, weak legs of these most aerial of birds. The tradition of depicting swifts without feet continued into the Middle Ages, as seen in the heraldic martlet.\u001b[0m\u001b[32;1m\u001b[1;3mThe scientific name for the hummingbird is **Trochilidae**, which is the biological family that includes approximately 366 species of hummingbirds.\n",
      "\n",
      "The fastest bird species is the **peregrine falcon** (*Falco peregrinus*), which can exceed speeds of 320 km/h (200 mph) during its dives. In terms of level flight, the common swift (*Apus apus*) holds the record for the fastest confirmed speed at 111.5 km/h (69.3 mph).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 1518\n",
      "Prompt Tokens: 1369\n",
      "Completion Tokens: 149\n",
      "Total Cost (USD): $0.00029475\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": \"What's a hummingbird's scientific name and what's the fastest bird species?\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
