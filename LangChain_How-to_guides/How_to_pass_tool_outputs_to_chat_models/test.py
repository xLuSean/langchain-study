from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool


llm = ChatOpenAI(model="gpt-4o-mini")

# >>> Define tools >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@tool
def add(a: int, b: int) ->int:
    """add a and b."""
    return a + b

@tool
def multiply(a: int, b: int) ->int:
    """multiply a and b."""
    return a * b

tools = [add, multiply]

tool_dict = {"add": add, "multiply": multiply}
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 * 12? Also, what is 11 + 49?"
messages = [HumanMessage(query)]

# >>> calculate which tool to call
ai_msg = llm_with_tools.invoke(messages)
# print(ai_msg.tool_calls)

messages.append(ai_msg)
# print(messages)

for tool_call in ai_msg.tool_calls:
    selected_tool = tool_dict[tool_call["name"].lower()]
    # call the tool
    tool_msg = selected_tool.invoke(tool_call)
    # print(tool_msg)
    # print(type(tool_msg))
    messages.append(tool_msg)


# messages now contains HumanMessage(original question) AIMessage(decide which tool to call), and ToolMessage(excution result of tools)
# AIMessage is generated by the model, ToolMessage is generated by the tool
# To gather all the messages, we can call the model again 
print(messages)
res = llm_with_tools.invoke(messages)

print(res)